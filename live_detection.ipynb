{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYqyzB9HfYD9"
   },
   "source": [
    "# Road Following - Live demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY2fbAERfYEE"
   },
   "source": [
    "In this notebook, we will use model we trained to move jetBot smoothly on track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLUIVC6wfYEF"
   },
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jnrKSUOZfYEI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2022-9-29 Python-3.6.9 torch-1.7.0 CUDA:0 (NVIDIA Tegra X1, 3964MiB)\n",
      "\n",
      "YOLOv5 🚀 2022-9-29 Python-3.6.9 torch-1.7.0 CUDA:0 (NVIDIA Tegra X1, 3964MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from yolov5.object_detect import run as object_detect_inference\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.torch_utils import select_device, smart_inference_mode\n",
    "from yolov5.utils.general import scale_coords, non_max_suppression\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "\n",
    "labels_to_names = {0:'Stop_Sign'}\n",
    "ob_device = select_device('cuda:0')\n",
    "ob_weights = 'best.pt' # best.pt 경로 설정\n",
    "ob_model = DetectMultiBackend(ob_weights, device=ob_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m39J6Sf6fYEL",
    "outputId": "5816ea79-5037-47e3-c776-6ddbd4af627a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_steering_model_xy_0920.pth')) # steering model명 기입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_mCFOrMfYEN"
   },
   "source": [
    "Currently, the model weights are located on the CPU memory execute the code below to transfer to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tn3CxLUDfYEO"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z72g24GXfYEP"
   },
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G7URFGeLfYEQ"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "def ob_preprocess(image):\n",
    "    image = np.array(image)\n",
    "    image = torch.from_numpy(image).to(device)\n",
    "    #image = transforms.functional.to_tensor(image).to(device)\n",
    "    image = image.half() if ob_model.fp16 else image.float()  # uint8 to fp16/32\n",
    "    image /= 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "    transform = transforms.Resize((640, 640))\n",
    "    image = transform(image)\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "3e4e8ba86e4e448d8a5c2e1d31b7fc81"
     ]
    },
    "id": "uDMSeZY0fYES",
    "outputId": "8465a5e2-f1b2-4188-ef68-f28f93c02180"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6528da0d74728af493d0f5079dd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPu_FF_FfYET"
   },
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VeOlRwa7fYEX",
    "outputId": "14d9a508-3774-4adf-bf8b-9225945b694e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object : 0, left_motor : 0.0, right_motor : -2.0129894801993284\n",
      "object : 0, left_motor : 0.2661047968419968, right_motor : 2.06906568842409\n",
      "object : 0, left_motor : 0.2675059203051101, right_motor : 2.0298342314569164\n",
      "object : 0, left_motor : 0.26732979150241387, right_motor : 2.034765837932411\n",
      "object : 0, left_motor : 0.2684392958564491, right_motor : 2.0036997160194248\n",
      "object : 0, left_motor : 0.266956829541244, right_motor : 2.0452087728451684\n",
      "object : 0, left_motor : 0.26660482755243636, right_motor : 2.0550648285317825\n",
      "object : 0, left_motor : 0.2669751684236802, right_motor : 2.0446952841369552\n",
      "object : 0, left_motor : 0.26551630326530024, right_motor : 2.0855435085715937\n",
      "object : 0, left_motor : 0.2668539823602303, right_motor : 2.048088493913553\n",
      "object : 0, left_motor : 0.26660916880463875, right_motor : 2.054943273470115\n",
      "object : 0, left_motor : 0.26707373319113253, right_motor : 2.0419354706482893\n",
      "object : 0, left_motor : 0.26548745657344086, right_motor : 2.0863512159436564\n",
      "object : 0, left_motor : 0.26611410895449705, right_motor : 2.0688049492740825\n",
      "object : 0, left_motor : 0.26559974820801824, right_motor : 2.0832070501754907\n",
      "object : 0, left_motor : 0.26592244188723757, right_motor : 2.0741716271573476\n",
      "object : 0, left_motor : 0.26651070293222345, right_motor : 2.0577003178977438\n",
      "object : 0, left_motor : 0.2666083884156115, right_motor : 2.054965124362879\n",
      "object : 0, left_motor : 0.2674219886192168, right_motor : 2.03218431866193\n",
      "object : 0, left_motor : 0.2663995427227429, right_motor : 2.0608128037632\n",
      "object : 0, left_motor : 0.26585251977807367, right_motor : 2.076129446213938\n",
      "object : 0, left_motor : 0.26539708893805875, right_motor : 2.088881509734355\n",
      "object : 0, left_motor : 0.2584286734106639, right_motor : 2.2839971445014116\n",
      "object : 0, left_motor : 0.2624454164875458, right_motor : 2.1715283383487183\n",
      "object : 0, left_motor : 0.2630528968446677, right_motor : 2.154518888349304\n",
      "object : 0, left_motor : 0.26488618443818995, right_motor : 2.1031868357306815\n",
      "object : 0, left_motor : 0.26294146515166783, right_motor : 2.1576389757533017\n",
      "object : 0, left_motor : 0.26333497443590453, right_motor : 2.1466207157946737\n",
      "object : 0, left_motor : 0.2642334904329161, right_motor : 2.121462267878349\n",
      "object : 0, left_motor : 0.26426592601185317, right_motor : 2.1205540716681117\n",
      "object : 0, left_motor : 0.2641246345756843, right_motor : 2.12451023188084\n",
      "object : 0, left_motor : 0.2646197431374665, right_motor : 2.110647192150939\n",
      "object : 0, left_motor : 0.2651237343520398, right_motor : 2.0965354381428867\n",
      "object : 0, left_motor : 0.26461643845142646, right_motor : 2.110739723360059\n",
      "object : 0, left_motor : 0.2642411951028242, right_motor : 2.1212465371209226\n",
      "object : 0, left_motor : 0.26451393495077546, right_motor : 2.113609821378287\n",
      "object : 0, left_motor : 0.26434534564518813, right_motor : 2.118330321934733\n",
      "object : 0, left_motor : 0.26507555835348307, right_motor : 2.0978843661024746\n",
      "object : 0, left_motor : 0.26416131464526255, right_motor : 2.1234831899326494\n",
      "object : 0, left_motor : 0.26321153940679876, right_motor : 2.150076896609636\n",
      "object : 0, left_motor : 0.2638917821898551, right_motor : 2.131030098684058\n",
      "object : 0, left_motor : 0.2646091667819024, right_motor : 2.110943330106733\n",
      "object : 0, left_motor : 0.2654310530474365, right_motor : 2.087930514671777\n",
      "object : 0, left_motor : 0.26765253763933267, right_motor : 2.025728946098685\n",
      "object : 0, left_motor : 0.26907149613342507, right_motor : 1.985998108264098\n",
      "object : 0, left_motor : 0.2671889514221417, right_motor : 2.0387093601800323\n",
      "object : 0, left_motor : 0.26751200479317555, right_motor : 2.0296638657910853\n",
      "object : 0, left_motor : 0.2678850678130632, right_motor : 2.019218101234231\n",
      "object : 0, left_motor : 0.2666871728765695, right_motor : 2.0527591594560546\n",
      "object : 0, left_motor : 0.26883579395587653, right_motor : 1.992597769235457\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "\n",
    "    speed_offset = 0.34 # 기본 speed\n",
    "    \n",
    "    angle_diff_bias = 0.1\n",
    "    angle = np.arctan2(x, y) # 핸들링 angle\n",
    "    if abs(angle) + angle_diff_bias < abs(angle_last): # 이전 angle보다 현재 angle이 더 작을경우\n",
    "        angle_temp = -1 * angle * 0.3\n",
    "    else: # \n",
    "        angle_temp = angle #이전 angle 보다 현재 angle이 더 클 경우\n",
    "    speed_value = speed_offset - abs(angle_temp) * 0.05 # 방향전환 상황에서는 속도를 낮춤\n",
    "    \n",
    "    if abs(angle_temp) < 0.05:\n",
    "        angle_temp = 0\n",
    "    \n",
    "    angle_last = angle\n",
    "    \n",
    "    angle_temp *= 1.4 # 핸들링 배율\n",
    "\n",
    "    # Yolo v5\n",
    "    pred = ob_model(ob_preprocess(image), augment=False)\n",
    "    \n",
    "    # NMS\n",
    "    pred = non_max_suppression(pred, conf_thres = 0.25, iou_thres = 0.45, classes = None, agnostic = False, max_det=1000)\n",
    "    \n",
    "    pred = pred[0] # => pred : bounding box 좌표(x1, y1, x2, y2), confidence score, class => total 6개의 값으로 나타남.\n",
    "\n",
    "    bbox_threshold = 0 # 설정해야할 값(bbox가 얼마나 클 때 장애물로 인식할 것인지?)\n",
    "    \n",
    "    bbox_count = 0\n",
    "    for *box, cf, cls in pred:\n",
    "        cf = cf.item()\n",
    "        cls = cls.item()\n",
    "\n",
    "        p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "        \n",
    "        bbox_area = (p2[0] - p1[0]) * (p2[1] - p1[1])\n",
    "        if bbox_area > bbox_threshold:\n",
    "            bbox_count = 1\n",
    "#     print(\"object : {}, left_motor : {}, right_motor : {}\".format(bbox_count, robot.left_motor.value, robot.right_motor.value))\n",
    "\n",
    "    if bbox_count > 0:\n",
    "      robot.left_motor.value = 0.0\n",
    "      robot.right_motor.value = angle_temp\n",
    "    else:\n",
    "      robot.left_motor.value = speed_value\n",
    "      robot.right_motor.value = angle_temp\n",
    "      \n",
    "    \n",
    "execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCyp7J0MfYEX"
   },
   "source": [
    "### Execution STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fBMwCOBdfYEY",
    "outputId": "b6f27aed-c45f-40dd-a2b5-e825995a3622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object : 0, left_motor : 0.2684451044387417, right_motor : 2.0035370757152338\n",
      "object : 0, left_motor : 0.0, right_motor : 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND_rBt02fYEY"
   },
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbw8DxjSfYEY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
