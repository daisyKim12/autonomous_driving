{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpz6tS2Bw5T3","executionInfo":{"status":"ok","timestamp":1668154672237,"user_tz":-540,"elapsed":31034,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}},"outputId":"a63e2b60-0ca5-428b-8f1e-4cbf0c5e3f2e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/yolo'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WkSEf_GxIIc","executionInfo":{"status":"ok","timestamp":1668154751097,"user_tz":-540,"elapsed":552,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}},"outputId":"a5f65449-0237-4e9d-d63b-25b48f822bc0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/yolo\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnimA2iivMT6"},"outputs":[],"source":["# Dataset download\n","!curl -L \"https://universe.roboflow.com/ds/3YzfC0NUOS?key=sRogD0aMQ1\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"lMcXAjx3vMUM","executionInfo":{"status":"ok","timestamp":1668154831305,"user_tz":-540,"elapsed":11,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}}},"outputs":[],"source":["# dataset ÌòïÏãùÏóê ÎßûÍ≤å Ïù¥Îèô\n","!mkdir dataset\n","!mv test dataset\n","!mv train dataset\n","!mv data.yaml dataset\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iyj_q7zvMUQ","executionInfo":{"status":"ok","timestamp":1668154914156,"user_tz":-540,"elapsed":1385,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}},"outputId":"2c539dff-dbd7-4da4-dcbb-e8f33710840c"},"outputs":[{"output_type":"stream","name":"stdout","text":["576 64\n","640\n"]}],"source":["from glob import glob\n","from sklearn.model_selection import train_test_split\n","\n","# image ÌååÏùºÎì§ÏùÑ train, validation setÏúºÎ°ú ÎÇòÎàà ÌõÑÏóê ÌååÏùºÏù¥Î¶Ñ listÌôî\n","img_list = glob('dataset/train/images/*.jpg')\n","\n","train_img_list, val_img_list = train_test_split(img_list, test_size=0.1, random_state=2000)\n","print(len(train_img_list), len(val_img_list))\n","print(len(img_list))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Kp492_rsvMUT","executionInfo":{"status":"ok","timestamp":1668154942461,"user_tz":-540,"elapsed":524,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}}},"outputs":[],"source":["# ÏúÑÏóêÏÑú ÏÉùÏÑ±Ìïú img_listÎ•º txt ÌååÏùºÎ°ú Ï†ÄÏû•\n","with open('dataset/train.txt', 'w') as f: # write\n","  f.write('\\n'.join(train_img_list) + '\\n')\n","\n","with open('dataset/val.txt', 'w') as f: # write\n","  f.write('\\n'.join(val_img_list) + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"dwlaCrxavMUV"},"source":["data.yaml Îç∞Ïù¥ÌÑ∞ ÏàòÏ†ï\n","\n","data.yaml ÌååÏùºÏóê ÏßÑÏûÖÌï¥ÏÑú\n","\n","(Before)\n","****************************\n","train: ../train/images\n","val: ../test/images\n","\n","nc: 1\n","names: ['0']\n","****************************\n","\n","(After)\n","****************************\n","train: /Users/yunsu/autonomous_project/jetbot/dataset/train.txt\n","val: /Users/yunsu/autonomous_project/jetbot/dataset/test.txt\n","\n","nc: 1\n","names: ['Stop sign']\n","****************************\n","\n","Îã§ÏùåÍ≥º Í∞ôÏù¥ ÏàòÏ†ï."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6dnVMpIvMUc","executionInfo":{"status":"ok","timestamp":1668155054428,"user_tz":-540,"elapsed":545,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}},"outputId":"cceb6d8a-046c-4f8c-e0cb-cade0c6047d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/yolo\n"]}],"source":["!pwd"]},{"cell_type":"markdown","metadata":{"id":"q-L-EpiSvMUg"},"source":["-- yolov5Ïùò train.py Í≤ΩÎ°ú ÏÑ§Ï†ï\n","\n","-- weights => pretrained weights download\n","\n","-- cfg => yolov5 Î™®Îç∏ Íµ¨Ï°∞ ÏÑ†ÌÉù\n","\n","-- data => Ïù¥Ï†ÑÏóê ÏÉùÏÑ±Ìïú data.yaml Í≤ΩÎ°ú\n","\n","-- epoch => training ÏãúÌÇ¨ epoch\n","\n","-- batch_size => batch_size Ïàò\n","\n","-- name => resultÎ°ú Ï†ÄÏû•Ìï† ÌååÏùºÏù¥Î¶Ñ\n","\n","-- img => image ÏÇ¨Ïù¥Ï¶à ÏÑ§Ï†ï"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EYjHyWkvMUj","executionInfo":{"status":"ok","timestamp":1668155850097,"user_tz":-540,"elapsed":406209,"user":{"displayName":"ÏÑ†ÏÉ§Ïù∏","userId":"03908017394417747553"}},"outputId":"d3b2babb-7164-40c2-9e15-4dc7b452cd11"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=yolov5/models/yolov5s.yaml, data=dataset/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=stop_sign_result, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","default message here: \u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n","YOLOv5 üöÄ 2022-11-11 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs in Weights & Biases\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 151MB/s]\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 270 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n","\n","Transferred 342/349 items from yolov5/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/yolo/dataset/train' images and labels...576 found, 0 missing, 0 empty, 0 corrupt: 100% 576/576 [00:01<00:00, 341.54it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/yolo/dataset/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/yolo/dataset/val' images and labels...64 found, 0 missing, 0 empty, 0 corrupt: 100% 64/64 [00:00<00:00, 228.10it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/yolo/dataset/val.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.62 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n","Plotting labels to yolov5/runs/train/stop_sign_result3/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/stop_sign_result3\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/29      3.71G    0.06336     0.0298          0         48        640: 100% 36/36 [00:13<00:00,  2.60it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:02<00:00,  1.15s/it]\n","                   all         64         64      0.606      0.656       0.75       0.51\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/29      4.61G    0.03799    0.02144          0         46        640: 100% 36/36 [00:10<00:00,  3.45it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.70it/s]\n","                   all         64         64      0.509      0.794       0.62      0.515\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/29      4.61G    0.03437    0.01506          0         46        640: 100% 36/36 [00:10<00:00,  3.42it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.27it/s]\n","                   all         64         64      0.542      0.953      0.634      0.588\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/29      4.61G    0.02997    0.01319          0         46        640: 100% 36/36 [00:10<00:00,  3.45it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.04it/s]\n","                   all         64         64      0.896      0.944      0.945      0.681\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/29      4.61G    0.02792    0.01231          0         55        640: 100% 36/36 [00:10<00:00,  3.40it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.40it/s]\n","                   all         64         64      0.923      0.941      0.959      0.772\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/29      4.61G    0.02244    0.01108          0         48        640: 100% 36/36 [00:10<00:00,  3.41it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.97it/s]\n","                   all         64         64      0.998      0.984      0.995      0.922\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/29      4.61G    0.01956    0.01025          0         49        640: 100% 36/36 [00:10<00:00,  3.35it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.22it/s]\n","                   all         64         64      0.998          1      0.995      0.716\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/29      4.61G    0.01763    0.01018          0         56        640: 100% 36/36 [00:10<00:00,  3.44it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.27it/s]\n","                   all         64         64      0.983          1      0.994      0.924\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/29      4.61G    0.01611   0.008939          0         47        640: 100% 36/36 [00:10<00:00,  3.29it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.62it/s]\n","                   all         64         64      0.984          1      0.993      0.711\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/29      4.61G    0.01458   0.008374          0         41        640: 100% 36/36 [00:10<00:00,  3.48it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.86it/s]\n","                   all         64         64      0.981          1      0.991       0.53\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/29      4.61G    0.01452   0.008407          0         50        640: 100% 36/36 [00:10<00:00,  3.39it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n","                   all         64         64      0.998          1      0.995      0.932\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/29      4.61G    0.01458    0.00776          0         47        640: 100% 36/36 [00:10<00:00,  3.50it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.23it/s]\n","                   all         64         64      0.998          1      0.995      0.594\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/29      4.61G    0.01202   0.007565          0         41        640: 100% 36/36 [00:12<00:00,  2.99it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.14it/s]\n","                   all         64         64      0.999          1      0.995      0.962\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/29      4.61G    0.01188    0.00795          0         51        640: 100% 36/36 [00:10<00:00,  3.36it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.17it/s]\n","                   all         64         64      0.999          1      0.995      0.882\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/29      4.61G      0.011   0.007491          0         56        640: 100% 36/36 [00:10<00:00,  3.49it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.98it/s]\n","                   all         64         64      0.999          1      0.995      0.916\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/29      4.61G      0.012   0.007203          0         49        640: 100% 36/36 [00:10<00:00,  3.47it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.24it/s]\n","                   all         64         64      0.999          1      0.995       0.73\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/29      4.61G    0.01009   0.006624          0         49        640: 100% 36/36 [00:10<00:00,  3.52it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.11it/s]\n","                   all         64         64      0.999          1      0.995      0.776\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/29      4.61G   0.009261   0.006738          0         49        640: 100% 36/36 [00:10<00:00,  3.37it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.63it/s]\n","                   all         64         64      0.999          1      0.995      0.734\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/29      4.61G    0.00877    0.00655          0         53        640: 100% 36/36 [00:10<00:00,  3.43it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.31it/s]\n","                   all         64         64      0.999          1      0.995      0.852\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/29      4.61G   0.009934   0.006728          0         52        640: 100% 36/36 [00:10<00:00,  3.40it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.49it/s]\n","                   all         64         64      0.999          1      0.995      0.894\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/29      4.61G   0.008581   0.005919          0         46        640: 100% 36/36 [00:10<00:00,  3.42it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n","                   all         64         64      0.999          1      0.995      0.914\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/29      4.61G   0.008774   0.006299          0         46        640: 100% 36/36 [00:10<00:00,  3.42it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.10it/s]\n","                   all         64         64      0.999          1      0.995       0.92\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/29      4.61G    0.00724    0.00608          0         43        640: 100% 36/36 [00:10<00:00,  3.45it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.03it/s]\n","                   all         64         64      0.999          1      0.995      0.986\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/29      4.61G   0.006618   0.005972          0         41        640: 100% 36/36 [00:10<00:00,  3.34it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.25it/s]\n","                   all         64         64      0.999          1      0.995      0.982\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/29      4.61G   0.007066   0.005898          0         45        640: 100% 36/36 [00:10<00:00,  3.39it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n","                   all         64         64      0.999          1      0.995      0.972\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/29      4.61G      0.007   0.005686          0         51        640: 100% 36/36 [00:10<00:00,  3.44it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.54it/s]\n","                   all         64         64      0.999          1      0.995       0.93\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/29      4.61G   0.006371   0.005511          0         47        640: 100% 36/36 [00:10<00:00,  3.44it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n","                   all         64         64      0.999          1      0.995      0.992\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/29      4.61G   0.005573   0.005331          0         49        640: 100% 36/36 [00:10<00:00,  3.40it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.89it/s]\n","                   all         64         64      0.999          1      0.995      0.981\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/29      4.61G   0.005693   0.005559          0         53        640: 100% 36/36 [00:10<00:00,  3.40it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n","                   all         64         64      0.999          1      0.995      0.976\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/29      4.61G   0.005498   0.005441          0         44        640: 100% 36/36 [00:10<00:00,  3.44it/s]\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.80it/s]\n","                   all         64         64      0.999          1      0.995      0.984\n","\n","30 epochs completed in 0.102 hours.\n","Optimizer stripped from yolov5/runs/train/stop_sign_result3/weights/last.pt, 14.5MB\n","Optimizer stripped from yolov5/runs/train/stop_sign_result3/weights/best.pt, 14.5MB\n","\n","Validating yolov5/runs/train/stop_sign_result3/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.77it/s]\n","                   all         64         64      0.999          1      0.995      0.992\n","Results saved to \u001b[1myolov5/runs/train/stop_sign_result3\u001b[0m\n"]}],"source":["\n","!python yolov5/train.py --weights yolov5/yolov5s.pt --cfg yolov5/models/yolov5s.yaml --data dataset/data.yaml --epochs 30 --batch-size 16 --name stop_sign_result --img 640"]},{"cell_type":"markdown","metadata":{"id":"lXwDJUHYvMUm"},"source":["training ÏôÑÎ£åÎêòÎ©¥ yolov5/runs/trainÏóêÏÑú training Í≤∞Í≥º Ï∞æÏùÑ Ïàò ÏûàÏùå."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oL7PghcdvMUp"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.13 ('ml')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"4b53a73392c5f8f1f6487298a1bef1bc1a5db0754328a847550455f6228573af"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}